{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from raxutil.ml.dataHandler import *\n",
    "from raxutil.ml.modelBuilder import *\n",
    "from raxutil.ml.templateAnalysis import *\n",
    "\n",
    "import cssutils\n",
    "from functools import reduce\n",
    "import os\n",
    "from os.path import basename\n",
    "import csv, ast\n",
    "from glob import glob\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.classify import MaxentClassifier \n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pymongo import TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"localhost:27017\")\n",
    "db=client.raxdb\n",
    "faresheet = 'CXfaresheets_new'\n",
    "fs = db['CXfaresheets_new']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Collect Training data from all markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect 8224 documents\n"
     ]
    }
   ],
   "source": [
    "collector = DataTransfer(db, faresheet)\n",
    "docs = collector.collect_for_train(classification=\"Commission\", country='ALL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .ml.dataHandler import DataTransformer\n",
    "transformer = DataTransformer()\n",
    "X_dat, Y_dat, files_index = transformer.data_construct(target_docs=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'no': 7405, 'yes': 752})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check imbalance\n",
    "from collections import Counter\n",
    "Counter(Y_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat, Y_dat, feature_names, feature_index = transformer.train_data_transform(X_dat, Y_dat, Y_map={'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset is very imbalanced, Over-Sampling the positive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=24)\n",
    "X_resampled, y_resampled = ros.fit_sample(X_dat, Y_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 7405, 1: 7405})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14810, 1138)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data to training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn y train to a numpy array\n",
    "y_train = np.array([[y, 1-y] for y in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([[y, 1-y] for y in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11848, 2)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11848, 1138)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make mini batches for training\n",
    "import math\n",
    "def make_batch(X_train, y_train, batch_size):\n",
    "    batch_num = math.floor(len(X_train) /batch_size)\n",
    "    for num in range(batch_num):\n",
    "        if num == batch_num-1:\n",
    "            index = range(0+batch_size*num, len(X_train))\n",
    "            yield X_train[index], y_train[index]\n",
    "        else:\n",
    "            index = range(0+batch_size*num, batch_size+batch_size*num)\n",
    "            yield X_train[index], y_train[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1]\n",
      " [2]]\n",
      "[[5 6]\n",
      " [7 6]]\n",
      "[[3]\n",
      " [1]]\n",
      "[[ 8  6]\n",
      " [ 9  6]\n",
      " [10  6]]\n",
      "[[2]\n",
      " [3]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "# test code\n",
    "test_x = np.array([[1,2], [3,4], [5,6], [7,6], [8,6], [9,6], [10,6]])\n",
    "test_y = np.array([[1], [2], [3], [1], [2], [3], [3]])\n",
    "for x, y in make_batch(test_x, test_y, 2):\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A three layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python optimisation variables\n",
    "learning_rate = 0.01\n",
    "epochs = 600\n",
    "batch_size = 100\n",
    "d=1138\n",
    "c=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the training data placeholders\n",
    "x = tf.placeholder(tf.float32, [None, d])\n",
    "# now declare the output data placeholder - 10 digits\n",
    "y = tf.placeholder(tf.float32, [None, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now declare the weights connecting the input to the hidden layer\n",
    "W1 = tf.Variable(tf.random_normal([d, 200], stddev=0.03), name='W1')\n",
    "b1 = tf.Variable(tf.random_normal([200]), name='b1')\n",
    "# and the weights connecting the hidden layer to the output layer\n",
    "W2 = tf.Variable(tf.random_normal([200, c], stddev=0.03), name='W2')\n",
    "b2 = tf.Variable(tf.random_normal([c]), name='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the output of the hidden layer\n",
    "hidden_out = tf.add(tf.matmul(x, W1), b1)\n",
    "hidden_out = tf.nn.relu(hidden_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the hidden layer output - in this case, let's use a softmax activated\n",
    "# output layer\n",
    "y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_out, W2), b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost or loss function for the optimisation/backpropagation\n",
    "y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999)\n",
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped) + (1 - y) * tf.log(1 - y_clipped), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an optimiser\n",
    "optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally setup the initialisation operator\n",
    "init_op = tf.global_variables_initializer()\n",
    "# define an accuracy assessment operation\n",
    "pred = tf.argmax(y_, 1)\n",
    "pred_prob = y_\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost = 0.644\n",
      "Epoch: 2 cost = 0.304\n",
      "Epoch: 3 cost = 0.211\n",
      "Epoch: 4 cost = 0.166\n",
      "Epoch: 5 cost = 0.139\n",
      "Epoch: 6 cost = 0.120\n",
      "Epoch: 7 cost = 0.105\n",
      "Epoch: 8 cost = 0.094\n",
      "Epoch: 9 cost = 0.084\n",
      "Epoch: 10 cost = 0.076\n",
      "Epoch: 11 cost = 0.070\n",
      "Epoch: 12 cost = 0.065\n",
      "Epoch: 13 cost = 0.060\n",
      "Epoch: 14 cost = 0.056\n",
      "Epoch: 15 cost = 0.053\n",
      "Epoch: 16 cost = 0.050\n",
      "Epoch: 17 cost = 0.047\n",
      "Epoch: 18 cost = 0.045\n",
      "Epoch: 19 cost = 0.043\n",
      "Epoch: 20 cost = 0.041\n",
      "Epoch: 21 cost = 0.039\n",
      "Epoch: 22 cost = 0.038\n",
      "Epoch: 23 cost = 0.036\n",
      "Epoch: 24 cost = 0.035\n",
      "Epoch: 25 cost = 0.034\n",
      "Epoch: 26 cost = 0.032\n",
      "Epoch: 27 cost = 0.031\n",
      "Epoch: 28 cost = 0.030\n",
      "Epoch: 29 cost = 0.029\n",
      "Epoch: 30 cost = 0.029\n",
      "Epoch: 31 cost = 0.028\n",
      "Epoch: 32 cost = 0.027\n",
      "Epoch: 33 cost = 0.026\n",
      "Epoch: 34 cost = 0.026\n",
      "Epoch: 35 cost = 0.025\n",
      "Epoch: 36 cost = 0.024\n",
      "Epoch: 37 cost = 0.024\n",
      "Epoch: 38 cost = 0.023\n",
      "Epoch: 39 cost = 0.023\n",
      "Epoch: 40 cost = 0.022\n",
      "Epoch: 41 cost = 0.022\n",
      "Epoch: 42 cost = 0.022\n",
      "Epoch: 43 cost = 0.021\n",
      "Epoch: 44 cost = 0.021\n",
      "Epoch: 45 cost = 0.020\n",
      "Epoch: 46 cost = 0.020\n",
      "Epoch: 47 cost = 0.020\n",
      "Epoch: 48 cost = 0.019\n",
      "Epoch: 49 cost = 0.019\n",
      "Epoch: 50 cost = 0.019\n",
      "Epoch: 51 cost = 0.018\n",
      "Epoch: 52 cost = 0.018\n",
      "Epoch: 53 cost = 0.018\n",
      "Epoch: 54 cost = 0.018\n",
      "Epoch: 55 cost = 0.017\n",
      "Epoch: 56 cost = 0.017\n",
      "Epoch: 57 cost = 0.017\n",
      "Epoch: 58 cost = 0.017\n",
      "Epoch: 59 cost = 0.016\n",
      "Epoch: 60 cost = 0.016\n",
      "Epoch: 61 cost = 0.016\n",
      "Epoch: 62 cost = 0.016\n",
      "Epoch: 63 cost = 0.015\n",
      "Epoch: 64 cost = 0.015\n",
      "Epoch: 65 cost = 0.015\n",
      "Epoch: 66 cost = 0.015\n",
      "Epoch: 67 cost = 0.015\n",
      "Epoch: 68 cost = 0.014\n",
      "Epoch: 69 cost = 0.014\n",
      "Epoch: 70 cost = 0.014\n",
      "Epoch: 71 cost = 0.014\n",
      "Epoch: 72 cost = 0.014\n",
      "Epoch: 73 cost = 0.014\n",
      "Epoch: 74 cost = 0.013\n",
      "Epoch: 75 cost = 0.013\n",
      "Epoch: 76 cost = 0.013\n",
      "Epoch: 77 cost = 0.013\n",
      "Epoch: 78 cost = 0.013\n",
      "Epoch: 79 cost = 0.013\n",
      "Epoch: 80 cost = 0.013\n",
      "Epoch: 81 cost = 0.012\n",
      "Epoch: 82 cost = 0.012\n",
      "Epoch: 83 cost = 0.012\n",
      "Epoch: 84 cost = 0.012\n",
      "Epoch: 85 cost = 0.012\n",
      "Epoch: 86 cost = 0.012\n",
      "Epoch: 87 cost = 0.012\n",
      "Epoch: 88 cost = 0.012\n",
      "Epoch: 89 cost = 0.011\n",
      "Epoch: 90 cost = 0.011\n",
      "Epoch: 91 cost = 0.011\n",
      "Epoch: 92 cost = 0.011\n",
      "Epoch: 93 cost = 0.011\n",
      "Epoch: 94 cost = 0.011\n",
      "Epoch: 95 cost = 0.011\n",
      "Epoch: 96 cost = 0.011\n",
      "Epoch: 97 cost = 0.011\n",
      "Epoch: 98 cost = 0.010\n",
      "Epoch: 99 cost = 0.010\n",
      "Epoch: 100 cost = 0.010\n",
      "Epoch: 101 cost = 0.010\n",
      "Epoch: 102 cost = 0.010\n",
      "Epoch: 103 cost = 0.010\n",
      "Epoch: 104 cost = 0.010\n",
      "Epoch: 105 cost = 0.010\n",
      "Epoch: 106 cost = 0.010\n",
      "Epoch: 107 cost = 0.010\n",
      "Epoch: 108 cost = 0.010\n",
      "Epoch: 109 cost = 0.009\n",
      "Epoch: 110 cost = 0.009\n",
      "Epoch: 111 cost = 0.009\n",
      "Epoch: 112 cost = 0.009\n",
      "Epoch: 113 cost = 0.009\n",
      "Epoch: 114 cost = 0.009\n",
      "Epoch: 115 cost = 0.009\n",
      "Epoch: 116 cost = 0.009\n",
      "Epoch: 117 cost = 0.009\n",
      "Epoch: 118 cost = 0.009\n",
      "Epoch: 119 cost = 0.009\n",
      "Epoch: 120 cost = 0.009\n",
      "Epoch: 121 cost = 0.009\n",
      "Epoch: 122 cost = 0.009\n",
      "Epoch: 123 cost = 0.008\n",
      "Epoch: 124 cost = 0.008\n",
      "Epoch: 125 cost = 0.008\n",
      "Epoch: 126 cost = 0.008\n",
      "Epoch: 127 cost = 0.008\n",
      "Epoch: 128 cost = 0.008\n",
      "Epoch: 129 cost = 0.008\n",
      "Epoch: 130 cost = 0.008\n",
      "Epoch: 131 cost = 0.008\n",
      "Epoch: 132 cost = 0.008\n",
      "Epoch: 133 cost = 0.008\n",
      "Epoch: 134 cost = 0.008\n",
      "Epoch: 135 cost = 0.008\n",
      "Epoch: 136 cost = 0.008\n",
      "Epoch: 137 cost = 0.008\n",
      "Epoch: 138 cost = 0.008\n",
      "Epoch: 139 cost = 0.007\n",
      "Epoch: 140 cost = 0.007\n",
      "Epoch: 141 cost = 0.007\n",
      "Epoch: 142 cost = 0.007\n",
      "Epoch: 143 cost = 0.007\n",
      "Epoch: 144 cost = 0.007\n",
      "Epoch: 145 cost = 0.007\n",
      "Epoch: 146 cost = 0.007\n",
      "Epoch: 147 cost = 0.007\n",
      "Epoch: 148 cost = 0.007\n",
      "Epoch: 149 cost = 0.007\n",
      "Epoch: 150 cost = 0.007\n",
      "Epoch: 151 cost = 0.007\n",
      "Epoch: 152 cost = 0.007\n",
      "Epoch: 153 cost = 0.007\n",
      "Epoch: 154 cost = 0.007\n",
      "Epoch: 155 cost = 0.007\n",
      "Epoch: 156 cost = 0.007\n",
      "Epoch: 157 cost = 0.007\n",
      "Epoch: 158 cost = 0.007\n",
      "Epoch: 159 cost = 0.007\n",
      "Epoch: 160 cost = 0.006\n",
      "Epoch: 161 cost = 0.006\n",
      "Epoch: 162 cost = 0.006\n",
      "Epoch: 163 cost = 0.006\n",
      "Epoch: 164 cost = 0.006\n",
      "Epoch: 165 cost = 0.006\n",
      "Epoch: 166 cost = 0.006\n",
      "Epoch: 167 cost = 0.006\n",
      "Epoch: 168 cost = 0.006\n",
      "Epoch: 169 cost = 0.006\n",
      "Epoch: 170 cost = 0.006\n",
      "Epoch: 171 cost = 0.006\n",
      "Epoch: 172 cost = 0.006\n",
      "Epoch: 173 cost = 0.006\n",
      "Epoch: 174 cost = 0.006\n",
      "Epoch: 175 cost = 0.006\n",
      "Epoch: 176 cost = 0.006\n",
      "Epoch: 177 cost = 0.006\n",
      "Epoch: 178 cost = 0.006\n",
      "Epoch: 179 cost = 0.006\n",
      "Epoch: 180 cost = 0.006\n",
      "Epoch: 181 cost = 0.006\n",
      "Epoch: 182 cost = 0.006\n",
      "Epoch: 183 cost = 0.006\n",
      "Epoch: 184 cost = 0.006\n",
      "Epoch: 185 cost = 0.006\n",
      "Epoch: 186 cost = 0.006\n",
      "Epoch: 187 cost = 0.006\n",
      "Epoch: 188 cost = 0.005\n",
      "Epoch: 189 cost = 0.005\n",
      "Epoch: 190 cost = 0.005\n",
      "Epoch: 191 cost = 0.005\n",
      "Epoch: 192 cost = 0.005\n",
      "Epoch: 193 cost = 0.005\n",
      "Epoch: 194 cost = 0.005\n",
      "Epoch: 195 cost = 0.005\n",
      "Epoch: 196 cost = 0.005\n",
      "Epoch: 197 cost = 0.005\n",
      "Epoch: 198 cost = 0.005\n",
      "Epoch: 199 cost = 0.005\n",
      "Epoch: 200 cost = 0.005\n",
      "Epoch: 201 cost = 0.005\n",
      "Epoch: 202 cost = 0.005\n",
      "Epoch: 203 cost = 0.005\n",
      "Epoch: 204 cost = 0.005\n",
      "Epoch: 205 cost = 0.005\n",
      "Epoch: 206 cost = 0.005\n",
      "Epoch: 207 cost = 0.005\n",
      "Epoch: 208 cost = 0.005\n",
      "Epoch: 209 cost = 0.005\n",
      "Epoch: 210 cost = 0.005\n",
      "Epoch: 211 cost = 0.005\n",
      "Epoch: 212 cost = 0.005\n",
      "Epoch: 213 cost = 0.005\n",
      "Epoch: 214 cost = 0.005\n",
      "Epoch: 215 cost = 0.005\n",
      "Epoch: 216 cost = 0.005\n",
      "Epoch: 217 cost = 0.005\n",
      "Epoch: 218 cost = 0.005\n",
      "Epoch: 219 cost = 0.005\n",
      "Epoch: 220 cost = 0.005\n",
      "Epoch: 221 cost = 0.005\n",
      "Epoch: 222 cost = 0.005\n",
      "Epoch: 223 cost = 0.005\n",
      "Epoch: 224 cost = 0.005\n",
      "Epoch: 225 cost = 0.005\n",
      "Epoch: 226 cost = 0.005\n",
      "Epoch: 227 cost = 0.004\n",
      "Epoch: 228 cost = 0.004\n",
      "Epoch: 229 cost = 0.004\n",
      "Epoch: 230 cost = 0.004\n",
      "Epoch: 231 cost = 0.004\n",
      "Epoch: 232 cost = 0.004\n",
      "Epoch: 233 cost = 0.004\n",
      "Epoch: 234 cost = 0.004\n",
      "Epoch: 235 cost = 0.004\n",
      "Epoch: 236 cost = 0.004\n",
      "Epoch: 237 cost = 0.004\n",
      "Epoch: 238 cost = 0.004\n",
      "Epoch: 239 cost = 0.004\n",
      "Epoch: 240 cost = 0.004\n",
      "Epoch: 241 cost = 0.004\n",
      "Epoch: 242 cost = 0.004\n",
      "Epoch: 243 cost = 0.004\n",
      "Epoch: 244 cost = 0.004\n",
      "Epoch: 245 cost = 0.004\n",
      "Epoch: 246 cost = 0.004\n",
      "Epoch: 247 cost = 0.004\n",
      "Epoch: 248 cost = 0.004\n",
      "Epoch: 249 cost = 0.004\n",
      "Epoch: 250 cost = 0.004\n",
      "Epoch: 251 cost = 0.004\n",
      "Epoch: 252 cost = 0.004\n",
      "Epoch: 253 cost = 0.004\n",
      "Epoch: 254 cost = 0.004\n",
      "Epoch: 255 cost = 0.004\n",
      "Epoch: 256 cost = 0.004\n",
      "Epoch: 257 cost = 0.004\n",
      "Epoch: 258 cost = 0.004\n",
      "Epoch: 259 cost = 0.004\n",
      "Epoch: 260 cost = 0.004\n",
      "Epoch: 261 cost = 0.004\n",
      "Epoch: 262 cost = 0.004\n",
      "Epoch: 263 cost = 0.004\n",
      "Epoch: 264 cost = 0.004\n",
      "Epoch: 265 cost = 0.004\n",
      "Epoch: 266 cost = 0.004\n",
      "Epoch: 267 cost = 0.004\n",
      "Epoch: 268 cost = 0.004\n",
      "Epoch: 269 cost = 0.004\n",
      "Epoch: 270 cost = 0.004\n",
      "Epoch: 271 cost = 0.004\n",
      "Epoch: 272 cost = 0.004\n",
      "Epoch: 273 cost = 0.004\n",
      "Epoch: 274 cost = 0.004\n",
      "Epoch: 275 cost = 0.004\n",
      "Epoch: 276 cost = 0.004\n",
      "Epoch: 277 cost = 0.004\n",
      "Epoch: 278 cost = 0.004\n",
      "Epoch: 279 cost = 0.004\n",
      "Epoch: 280 cost = 0.004\n",
      "Epoch: 281 cost = 0.004\n",
      "Epoch: 282 cost = 0.004\n",
      "Epoch: 283 cost = 0.004\n",
      "Epoch: 284 cost = 0.004\n",
      "Epoch: 285 cost = 0.004\n",
      "Epoch: 286 cost = 0.004\n",
      "Epoch: 287 cost = 0.003\n",
      "Epoch: 288 cost = 0.003\n",
      "Epoch: 289 cost = 0.003\n",
      "Epoch: 290 cost = 0.003\n",
      "Epoch: 291 cost = 0.003\n",
      "Epoch: 292 cost = 0.003\n",
      "Epoch: 293 cost = 0.003\n",
      "Epoch: 294 cost = 0.003\n",
      "Epoch: 295 cost = 0.003\n",
      "Epoch: 296 cost = 0.003\n",
      "Epoch: 297 cost = 0.003\n",
      "Epoch: 298 cost = 0.003\n",
      "Epoch: 299 cost = 0.003\n",
      "Epoch: 300 cost = 0.003\n",
      "Epoch: 301 cost = 0.003\n",
      "Epoch: 302 cost = 0.003\n",
      "Epoch: 303 cost = 0.003\n",
      "Epoch: 304 cost = 0.003\n",
      "Epoch: 305 cost = 0.003\n",
      "Epoch: 306 cost = 0.003\n",
      "Epoch: 307 cost = 0.003\n",
      "Epoch: 308 cost = 0.003\n",
      "Epoch: 309 cost = 0.003\n",
      "Epoch: 310 cost = 0.003\n",
      "Epoch: 311 cost = 0.003\n",
      "Epoch: 312 cost = 0.003\n",
      "Epoch: 313 cost = 0.003\n",
      "Epoch: 314 cost = 0.003\n",
      "Epoch: 315 cost = 0.003\n",
      "Epoch: 316 cost = 0.003\n",
      "Epoch: 317 cost = 0.003\n",
      "Epoch: 318 cost = 0.003\n",
      "Epoch: 319 cost = 0.003\n",
      "Epoch: 320 cost = 0.003\n",
      "Epoch: 321 cost = 0.003\n",
      "Epoch: 322 cost = 0.003\n",
      "Epoch: 323 cost = 0.003\n",
      "Epoch: 324 cost = 0.003\n",
      "Epoch: 325 cost = 0.003\n",
      "Epoch: 326 cost = 0.003\n",
      "Epoch: 327 cost = 0.003\n",
      "Epoch: 328 cost = 0.003\n",
      "Epoch: 329 cost = 0.003\n",
      "Epoch: 330 cost = 0.003\n",
      "Epoch: 331 cost = 0.003\n",
      "Epoch: 332 cost = 0.003\n",
      "Epoch: 333 cost = 0.003\n",
      "Epoch: 334 cost = 0.003\n",
      "Epoch: 335 cost = 0.003\n",
      "Epoch: 336 cost = 0.003\n",
      "Epoch: 337 cost = 0.003\n",
      "Epoch: 338 cost = 0.003\n",
      "Epoch: 339 cost = 0.003\n",
      "Epoch: 340 cost = 0.003\n",
      "Epoch: 341 cost = 0.003\n",
      "Epoch: 342 cost = 0.003\n",
      "Epoch: 343 cost = 0.003\n",
      "Epoch: 344 cost = 0.003\n",
      "Epoch: 345 cost = 0.003\n",
      "Epoch: 346 cost = 0.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 347 cost = 0.003\n",
      "Epoch: 348 cost = 0.003\n",
      "Epoch: 349 cost = 0.003\n",
      "Epoch: 350 cost = 0.003\n",
      "Epoch: 351 cost = 0.003\n",
      "Epoch: 352 cost = 0.003\n",
      "Epoch: 353 cost = 0.003\n",
      "Epoch: 354 cost = 0.003\n",
      "Epoch: 355 cost = 0.003\n",
      "Epoch: 356 cost = 0.003\n",
      "Epoch: 357 cost = 0.003\n",
      "Epoch: 358 cost = 0.003\n",
      "Epoch: 359 cost = 0.003\n",
      "Epoch: 360 cost = 0.003\n",
      "Epoch: 361 cost = 0.003\n",
      "Epoch: 362 cost = 0.003\n",
      "Epoch: 363 cost = 0.003\n",
      "Epoch: 364 cost = 0.003\n",
      "Epoch: 365 cost = 0.003\n",
      "Epoch: 366 cost = 0.003\n",
      "Epoch: 367 cost = 0.003\n",
      "Epoch: 368 cost = 0.003\n",
      "Epoch: 369 cost = 0.003\n",
      "Epoch: 370 cost = 0.003\n",
      "Epoch: 371 cost = 0.003\n",
      "Epoch: 372 cost = 0.003\n",
      "Epoch: 373 cost = 0.003\n",
      "Epoch: 374 cost = 0.003\n",
      "Epoch: 375 cost = 0.003\n",
      "Epoch: 376 cost = 0.003\n",
      "Epoch: 377 cost = 0.003\n",
      "Epoch: 378 cost = 0.003\n",
      "Epoch: 379 cost = 0.003\n",
      "Epoch: 380 cost = 0.003\n",
      "Epoch: 381 cost = 0.003\n",
      "Epoch: 382 cost = 0.003\n",
      "Epoch: 383 cost = 0.003\n",
      "Epoch: 384 cost = 0.003\n",
      "Epoch: 385 cost = 0.003\n",
      "Epoch: 386 cost = 0.003\n",
      "Epoch: 387 cost = 0.003\n",
      "Epoch: 388 cost = 0.003\n",
      "Epoch: 389 cost = 0.003\n",
      "Epoch: 390 cost = 0.003\n",
      "Epoch: 391 cost = 0.003\n",
      "Epoch: 392 cost = 0.003\n",
      "Epoch: 393 cost = 0.003\n",
      "Epoch: 394 cost = 0.003\n",
      "Epoch: 395 cost = 0.003\n",
      "Epoch: 396 cost = 0.002\n",
      "Epoch: 397 cost = 0.002\n",
      "Epoch: 398 cost = 0.002\n",
      "Epoch: 399 cost = 0.002\n",
      "Epoch: 400 cost = 0.002\n",
      "Epoch: 401 cost = 0.002\n",
      "Epoch: 402 cost = 0.002\n",
      "Epoch: 403 cost = 0.002\n",
      "Epoch: 404 cost = 0.002\n",
      "Epoch: 405 cost = 0.002\n",
      "Epoch: 406 cost = 0.002\n",
      "Epoch: 407 cost = 0.002\n",
      "Epoch: 408 cost = 0.002\n",
      "Epoch: 409 cost = 0.002\n",
      "Epoch: 410 cost = 0.002\n",
      "Epoch: 411 cost = 0.002\n",
      "Epoch: 412 cost = 0.002\n",
      "Epoch: 413 cost = 0.002\n",
      "Epoch: 414 cost = 0.002\n",
      "Epoch: 415 cost = 0.002\n",
      "Epoch: 416 cost = 0.002\n",
      "Epoch: 417 cost = 0.002\n",
      "Epoch: 418 cost = 0.002\n",
      "Epoch: 419 cost = 0.002\n",
      "Epoch: 420 cost = 0.002\n",
      "Epoch: 421 cost = 0.002\n",
      "Epoch: 422 cost = 0.002\n",
      "Epoch: 423 cost = 0.002\n",
      "Epoch: 424 cost = 0.002\n",
      "Epoch: 425 cost = 0.002\n",
      "Epoch: 426 cost = 0.002\n",
      "Epoch: 427 cost = 0.002\n",
      "Epoch: 428 cost = 0.002\n",
      "Epoch: 429 cost = 0.002\n",
      "Epoch: 430 cost = 0.002\n",
      "Epoch: 431 cost = 0.002\n",
      "Epoch: 432 cost = 0.002\n",
      "Epoch: 433 cost = 0.002\n",
      "Epoch: 434 cost = 0.002\n",
      "Epoch: 435 cost = 0.002\n",
      "Epoch: 436 cost = 0.002\n",
      "Epoch: 437 cost = 0.002\n",
      "Epoch: 438 cost = 0.002\n",
      "Epoch: 439 cost = 0.002\n",
      "Epoch: 440 cost = 0.002\n",
      "Epoch: 441 cost = 0.002\n",
      "Epoch: 442 cost = 0.002\n",
      "Epoch: 443 cost = 0.002\n",
      "Epoch: 444 cost = 0.002\n",
      "Epoch: 445 cost = 0.002\n",
      "Epoch: 446 cost = 0.002\n",
      "Epoch: 447 cost = 0.002\n",
      "Epoch: 448 cost = 0.002\n",
      "Epoch: 449 cost = 0.002\n",
      "Epoch: 450 cost = 0.002\n",
      "Epoch: 451 cost = 0.002\n",
      "Epoch: 452 cost = 0.002\n",
      "Epoch: 453 cost = 0.002\n",
      "Epoch: 454 cost = 0.002\n",
      "Epoch: 455 cost = 0.002\n",
      "Epoch: 456 cost = 0.002\n",
      "Epoch: 457 cost = 0.002\n",
      "Epoch: 458 cost = 0.002\n",
      "Epoch: 459 cost = 0.002\n",
      "Epoch: 460 cost = 0.002\n",
      "Epoch: 461 cost = 0.002\n",
      "Epoch: 462 cost = 0.002\n",
      "Epoch: 463 cost = 0.002\n",
      "Epoch: 464 cost = 0.002\n",
      "Epoch: 465 cost = 0.002\n",
      "Epoch: 466 cost = 0.002\n",
      "Epoch: 467 cost = 0.002\n",
      "Epoch: 468 cost = 0.002\n",
      "Epoch: 469 cost = 0.002\n",
      "Epoch: 470 cost = 0.002\n",
      "Epoch: 471 cost = 0.002\n",
      "Epoch: 472 cost = 0.002\n",
      "Epoch: 473 cost = 0.002\n",
      "Epoch: 474 cost = 0.002\n",
      "Epoch: 475 cost = 0.002\n",
      "Epoch: 476 cost = 0.002\n",
      "Epoch: 477 cost = 0.002\n",
      "Epoch: 478 cost = 0.002\n",
      "Epoch: 479 cost = 0.002\n",
      "Epoch: 480 cost = 0.002\n",
      "Epoch: 481 cost = 0.002\n",
      "Epoch: 482 cost = 0.002\n",
      "Epoch: 483 cost = 0.002\n",
      "Epoch: 484 cost = 0.002\n",
      "Epoch: 485 cost = 0.002\n",
      "Epoch: 486 cost = 0.002\n",
      "Epoch: 487 cost = 0.002\n",
      "Epoch: 488 cost = 0.002\n",
      "Epoch: 489 cost = 0.002\n",
      "Epoch: 490 cost = 0.002\n",
      "Epoch: 491 cost = 0.002\n",
      "Epoch: 492 cost = 0.002\n",
      "Epoch: 493 cost = 0.002\n",
      "Epoch: 494 cost = 0.002\n",
      "Epoch: 495 cost = 0.002\n",
      "Epoch: 496 cost = 0.002\n",
      "Epoch: 497 cost = 0.002\n",
      "Epoch: 498 cost = 0.002\n",
      "Epoch: 499 cost = 0.002\n",
      "Epoch: 500 cost = 0.002\n",
      "Epoch: 501 cost = 0.002\n",
      "Epoch: 502 cost = 0.002\n",
      "Epoch: 503 cost = 0.002\n",
      "Epoch: 504 cost = 0.002\n",
      "Epoch: 505 cost = 0.002\n",
      "Epoch: 506 cost = 0.002\n",
      "Epoch: 507 cost = 0.002\n",
      "Epoch: 508 cost = 0.002\n",
      "Epoch: 509 cost = 0.002\n",
      "Epoch: 510 cost = 0.002\n",
      "Epoch: 511 cost = 0.002\n",
      "Epoch: 512 cost = 0.002\n",
      "Epoch: 513 cost = 0.002\n",
      "Epoch: 514 cost = 0.002\n",
      "Epoch: 515 cost = 0.002\n",
      "Epoch: 516 cost = 0.002\n",
      "Epoch: 517 cost = 0.002\n",
      "Epoch: 518 cost = 0.002\n",
      "Epoch: 519 cost = 0.002\n",
      "Epoch: 520 cost = 0.002\n",
      "Epoch: 521 cost = 0.002\n",
      "Epoch: 522 cost = 0.002\n",
      "Epoch: 523 cost = 0.002\n",
      "Epoch: 524 cost = 0.002\n",
      "Epoch: 525 cost = 0.002\n",
      "Epoch: 526 cost = 0.002\n",
      "Epoch: 527 cost = 0.002\n",
      "Epoch: 528 cost = 0.002\n",
      "Epoch: 529 cost = 0.002\n",
      "Epoch: 530 cost = 0.002\n",
      "Epoch: 531 cost = 0.002\n",
      "Epoch: 532 cost = 0.002\n",
      "Epoch: 533 cost = 0.002\n",
      "Epoch: 534 cost = 0.002\n",
      "Epoch: 535 cost = 0.002\n",
      "Epoch: 536 cost = 0.002\n",
      "Epoch: 537 cost = 0.002\n",
      "Epoch: 538 cost = 0.002\n",
      "Epoch: 539 cost = 0.002\n",
      "Epoch: 540 cost = 0.002\n",
      "Epoch: 541 cost = 0.002\n",
      "Epoch: 542 cost = 0.002\n",
      "Epoch: 543 cost = 0.002\n",
      "Epoch: 544 cost = 0.002\n",
      "Epoch: 545 cost = 0.002\n",
      "Epoch: 546 cost = 0.002\n",
      "Epoch: 547 cost = 0.002\n",
      "Epoch: 548 cost = 0.002\n",
      "Epoch: 549 cost = 0.002\n",
      "Epoch: 550 cost = 0.002\n",
      "Epoch: 551 cost = 0.002\n",
      "Epoch: 552 cost = 0.002\n",
      "Epoch: 553 cost = 0.002\n",
      "Epoch: 554 cost = 0.002\n",
      "Epoch: 555 cost = 0.002\n",
      "Epoch: 556 cost = 0.002\n",
      "Epoch: 557 cost = 0.002\n",
      "Epoch: 558 cost = 0.002\n",
      "Epoch: 559 cost = 0.002\n",
      "Epoch: 560 cost = 0.002\n",
      "Epoch: 561 cost = 0.002\n",
      "Epoch: 562 cost = 0.002\n",
      "Epoch: 563 cost = 0.002\n",
      "Epoch: 564 cost = 0.002\n",
      "Epoch: 565 cost = 0.002\n",
      "Epoch: 566 cost = 0.002\n",
      "Epoch: 567 cost = 0.002\n",
      "Epoch: 568 cost = 0.002\n",
      "Epoch: 569 cost = 0.002\n",
      "Epoch: 570 cost = 0.002\n",
      "Epoch: 571 cost = 0.002\n",
      "Epoch: 572 cost = 0.002\n",
      "Epoch: 573 cost = 0.002\n",
      "Epoch: 574 cost = 0.002\n",
      "Epoch: 575 cost = 0.002\n",
      "Epoch: 576 cost = 0.002\n",
      "Epoch: 577 cost = 0.002\n",
      "Epoch: 578 cost = 0.002\n",
      "Epoch: 579 cost = 0.002\n",
      "Epoch: 580 cost = 0.002\n",
      "Epoch: 581 cost = 0.002\n",
      "Epoch: 582 cost = 0.002\n",
      "Epoch: 583 cost = 0.002\n",
      "Epoch: 584 cost = 0.002\n",
      "Epoch: 585 cost = 0.002\n",
      "Epoch: 586 cost = 0.002\n",
      "Epoch: 587 cost = 0.002\n",
      "Epoch: 588 cost = 0.002\n",
      "Epoch: 589 cost = 0.002\n",
      "Epoch: 590 cost = 0.002\n",
      "Epoch: 591 cost = 0.002\n",
      "Epoch: 592 cost = 0.002\n",
      "Epoch: 593 cost = 0.002\n",
      "Epoch: 594 cost = 0.002\n",
      "Epoch: 595 cost = 0.002\n",
      "Epoch: 596 cost = 0.002\n",
      "Epoch: 597 cost = 0.002\n",
      "Epoch: 598 cost = 0.002\n",
      "Epoch: 599 cost = 0.002\n",
      "Epoch: 600 cost = 0.002\n",
      "0.9966239\n",
      "[ True  True  True ...  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "with tf.Session() as sess:\n",
    "    # initialise the variables \n",
    "    sess.run(init_op)\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost=0\n",
    "        for batch_x, batch_y in make_batch(X_train, y_train, batch_size):\n",
    "            _, c = sess.run([optimiser, cross_entropy], feed_dict={x: batch_x, y: batch_y})\n",
    "            batch_num = math.floor(len(X_train) /batch_size)\n",
    "            avg_cost += c/batch_num \n",
    "        print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost))\n",
    "    print(sess.run(accuracy, feed_dict={x: X_test, y: y_test}))\n",
    "    print(sess.run(correct_prediction, feed_dict={x: X_test, y: y_test}))\n",
    "    preds = sess.run(pred, feed_dict={x: X_test, y: y_test})\n",
    "    preds_probs = sess.run(pred_prob, feed_dict={x: X_test, y: y_test})\n",
    "      \n",
    "    #golds = sess.run(gold, feed_dict={x: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
