{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#from raxutil.nlp.faresheet import *\n",
    "#from raxutil.nlp.production import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cssutils\n",
    "from functools import reduce\n",
    "import os\n",
    "from os.path import basename\n",
    "import csv, ast\n",
    "from glob import glob\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.classify import MaxentClassifier \n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pymongo import TEXT\n",
    "pd.options.display.max_rows = 99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost:27017')\n",
    "db=client.raxdb\n",
    "faresheet = 'CXfaresheets_new'\n",
    "faresheet_old = 'CXfaresheets' \n",
    "fs = db['CXfaresheets_new']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify different templates of US commission sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_docs = [doc for doc in fs.find({'country': 'US'}, \n",
    "                                  {'predictions':1, 'classifications':1, 'filename':1, 'country':1})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1405"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(us_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df = pd.DataFrame(us_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in us_df.iterrows():\n",
    "    try:\n",
    "        us_df.loc[index, 'gold'] = row['classifications']['Commission']\n",
    "    except:\n",
    "        print(\"Can't get commission gold: \", row)\n",
    "    us_df.loc[index, 'pred'] = row['predictions']['Commission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the predicted commission sheet\n",
    "mask1 = us_df['gold']=='yes'\n",
    "mask2 = us_df['pred']=='yes'\n",
    "us_comm = us_df.loc[mask1|mask2]\n",
    "mask3 = us_df['gold']!='no'\n",
    "us_comm = us_comm.loc[mask3]\n",
    "us_comm.drop(['classifications', 'predictions'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in us_comm.iterrows():\n",
    "    text = fs.find_one({'_id': row['_id']}, {'teststring':1})\n",
    "    us_comm.loc[index, 'teststring'] = text['teststring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=3, lowercase=False,\n",
    "                                   stop_words='english', analyzer='word')\n",
    "tfidf = tfidf_vectorizer.fit_transform(us_comm['teststring'])\n",
    "tfidf_feature_list = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7702"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km_model = KMeans(n_clusters=2)\n",
    "km_model.fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 7702)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_comm['cluster'] = km_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_comm.to_csv('/Users/chenjialu/Desktop/commission_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_comm.sort_values(by=['cluster', 'filename'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100 \n",
    "us_comm[['filename', 'cluster']].loc[us_comm['cluster']==1].to_csv('/Users/chenjialu/Desktop/commission_templateA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_comm = pd.read_csv('/Users/chenjialu/Desktop/commission_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take cluster 0 to further split \n",
    "us_comm2 = us_comm.loc[us_comm['cluster']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=10, lowercase=False,\n",
    "                                   stop_words='english', analyzer='word')\n",
    "tfidf = tfidf_vectorizer.fit_transform(us_comm2['teststring'])\n",
    "tfidf_feature_list = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 1980)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km_model = KMeans(n_clusters=4)\n",
    "km_model.fit(tfidf)\n",
    "clustering = collections.defaultdict(list)\n",
    "for idx, label in enumerate(km_model.labels_):\n",
    "        clustering[label].append((us_comm2.iloc[idx]['filename'], us_comm2.iloc[idx]['country'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/rassure_nltk/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# labels = [3 if i==1 else 0 for i in km_model.labels_]\n",
    "us_comm2['cluster'] = km_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/rassure_nltk/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "us_comm2.sort_values(by=['cluster', 'filename'], inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/rassure_nltk/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "us_comm2['template'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/rassure_nltk/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# mark incentive agreement as template A\n",
    "us_comm2.loc[us_comm2['teststring'].str.contains('INCENTIVE AGREEMENT'), 'template'] = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_comm2[['filename', 'cluster', 'template']].to_csv('/Users/chenjialu/Desktop/other_templates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add file path in the check list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_comm = pd.read_csv('/Users/chenjialu/Desktop/CX_Commissions/Predicted Commissions/US/commission_check_US1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_comm['filepath']=''\n",
    "us_comm['manual check']=''\n",
    "us_comm['human prediction']=''\n",
    "us_comm['model prediction']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['filename', 'cluster', 'template', 'filepath', 'human prediction', 'model prediction', 'manual check']\n",
    "us_comm = us_comm[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_comm.to_csv('/Users/chenjialu/Desktop/CX_Commissions/Predicted Commissions/US/commission_check_US1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_comm(db, faresheet, country):\n",
    "    us_docs = [doc for doc in db[faresheet].find({'country': country}, \n",
    "                                  {'predictions':1, 'classifications':1, 'path':1, 'teststring':1, 'filename':1, 'country':1})]\n",
    "    us_df = pd.DataFrame(us_docs)\n",
    "    us_df['gold'] = ''\n",
    "    # labelling\n",
    "    for index, row in us_df.iterrows():\n",
    "        try:\n",
    "            us_df.loc[index, 'gold'] = row['classifications']['Commission']\n",
    "        except:\n",
    "            print(\"Can't get commission gold: \", row['filename'])\n",
    "        us_df.loc[index, 'pred'] = row['predictions']['Commission']\n",
    "        \n",
    "    # get all the predicted/classified commission sheet\n",
    "    mask1 = us_df['gold']=='yes'\n",
    "    mask2 = us_df['pred']=='yes'\n",
    "    us_comm = us_df.loc[mask1|mask2]\n",
    "    mask3 = us_df['gold']!='no'\n",
    "    us_comm = us_comm.loc[mask3]\n",
    "    us_comm.drop(['classifications', 'predictions'], axis=1, inplace=True)\n",
    "    \n",
    "    return us_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "def tfidf_cluster(us_comm, k=2, v_min_df=2):\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=v_min_df, lowercase=False,\n",
    "                                   stop_words='english', analyzer='word')\n",
    "    tfidf = tfidf_vectorizer.fit_transform(us_comm['teststring'])\n",
    "    tfidf_feature_list = tfidf_vectorizer.get_feature_names()\n",
    "    print(\"Number of features: \", len(tfidf_feature_list))\n",
    "    km_model = KMeans(n_clusters=k)\n",
    "    km_model.fit(tfidf)\n",
    "    us_comm['cluster'] = km_model.labels_\n",
    "    us_comm.sort_values(['cluster', 'filename'], inplace=True)\n",
    "    return us_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "def choose_k(dat_comm, k1=2, k2=11, v_min_df=2):\n",
    "    \"\"\"A function to choose k with tfidf, A higher Silhouette Coefficient indicates that the object is well matched to \n",
    "    its own cluster and poorly matched to neighboring clusters.\"\"\"\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=v_min_df, lowercase=False,\n",
    "                                   stop_words='english', analyzer='word')\n",
    "    tfidf = tfidf_vectorizer.fit_transform(dat_comm['teststring'])\n",
    "    tfidf_feature_list = tfidf_vectorizer.get_feature_names()\n",
    "    print(\"Number of features: \", len(tfidf_feature_list))\n",
    "    for n_cluster in range(k1, k2):\n",
    "        kmeans = KMeans(n_clusters=n_cluster).fit(tfidf)\n",
    "        label = kmeans.labels_\n",
    "        sil_coeff = silhouette_score(tfidf, label, metric='euclidean')\n",
    "        print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(n_cluster, sil_coeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_checklist(us_comm, country):\n",
    "    new_comm = us_comm.copy()\n",
    "    # add filepath\n",
    "    for index, row in us_comm.iterrows():\n",
    "        us_doc = [doc for doc in fs.find({'filename': row['filename'], 'country': country}, \n",
    "                                   {'path':1, 'predictions':1, 'classifications':1} )][0]        \n",
    "        new_comm.loc[index, 'filepath'] = us_doc['path']\n",
    "#         try:\n",
    "#             us_comm.loc[index, 'human prediction'] = us_doc['classifications']['Commission']\n",
    "#         except:\n",
    "#             print(\"no human classification for: \", row['filename'])\n",
    "        #us_comm.loc[index, 'model prediction'] = us_doc['predictions']['Commission']\n",
    "    return new_comm\n",
    "    \n",
    "# au_comm=create_checklist(au_comm, 'AU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Example for a market:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz_comm = get_market_comm(db, faresheet, 'NZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters=2, The Silhouette Coefficient is 0.4538953197427514\n",
      "For n_clusters=3, The Silhouette Coefficient is 0.44097637723692046\n",
      "For n_clusters=4, The Silhouette Coefficient is 0.4745091049347023\n",
      "For n_clusters=5, The Silhouette Coefficient is 0.5151229959523871\n",
      "For n_clusters=6, The Silhouette Coefficient is 0.5409860794471184\n",
      "For n_clusters=7, The Silhouette Coefficient is 0.5656425679343441\n",
      "For n_clusters=8, The Silhouette Coefficient is 0.5840518082361282\n",
      "For n_clusters=9, The Silhouette Coefficient is 0.5657587513455863\n"
     ]
    }
   ],
   "source": [
    "choose_k(nz_comm, k1=2, k2=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose k as 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  1134\n"
     ]
    }
   ],
   "source": [
    "nz_comm=tfidf_cluster(nz_comm, k=4, v_min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz_comm[['filename', 'pred', 'gold', 'cluster', 'path']].to_csv('/Users/chenjialu/Desktop/commission_check.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rassure_nltk]",
   "language": "python",
   "name": "conda-env-rassure_nltk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
