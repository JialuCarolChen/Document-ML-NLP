{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cssutils\n",
    "from functools import reduce\n",
    "import os\n",
    "from os.path import basename\n",
    "import csv, ast\n",
    "from glob import glob\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.classify import MaxentClassifier \n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pymongo import TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost:27017')\n",
    "db=client.raxdb\n",
    "faresheet = 'CXfaresheets_new'\n",
    "fs = db['CXfaresheets_new']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0.1 Find manually created classifications\n",
    "docs = [doc for doc in fs.find({'classifications.Commission': {\"$exists\": True}}, \n",
    "                               {'classifications':1, 'filename':1, 'country':1})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_convert(docs, target_class):\n",
    "    \"\"\"\n",
    "    a function convert mongo classifications documents to data frame\n",
    "    @param cols: a list of classification columns to include\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(docs)\n",
    "    cols = list((df.columns))\n",
    "    cols.remove('classifications')\n",
    "    if cols == []:  \n",
    "        cols += list(docs[0]['classifications'].keys())\n",
    "    else:\n",
    "        cols.append(target_class)\n",
    "        \n",
    "    df = pd.concat([df.drop(['classifications'], axis=1), df['classifications'].apply(pd.Series)], axis=1)\n",
    "    df = df[cols]\n",
    "    # filter out undefined entries \n",
    "    df = df[df[target_class]!='Commission']    \n",
    "    return df\n",
    "dat = docs_convert(docs, 'Commission')\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean undefined data\n",
    "dat = dat.loc[dat['Commission']!='undefined']\n",
    "print(len(dat))\n",
    "dat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag training data\n",
    "cnt = 0\n",
    "for index, row in dat.iterrows():\n",
    "    fs.update_one({'_id': row['_id']},\n",
    "                  {\"$set\": {'cases.commission_classification': 'training'}}\n",
    "                 )\n",
    "    cnt = cnt+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some options to consider to deal with the lack of samples problem: \n",
    "- leave-one-out cross validation\n",
    "- bagging and bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct data for modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs = [doc for doc in fs.find({'cases.commission_classification': \"training\"}, \n",
    "docs = [doc for doc in fs.find({'$or': [ { 'classifications.Commission': 'yes' }, { 'classifications.Commission': 'no' }]}, \n",
    "                               {'tc_features':1, 'topword_features':1, 'classifications':1, 'filename':1, 'country':1})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_construct(target_docs, feature_list, mode, class_n=\"\", labels=[]):\n",
    "    \"\"\"\n",
    "    a function convert mongo classifications documents to data frame\n",
    "    \n",
    "    @param feature_list: a list of classification features to include\n",
    "    @param docs: mongodb documents which contain the following fields: _id, filename, country and features\n",
    "    @param labels: a list of valid labelling values\n",
    "    @param class_n: name of the classification task\n",
    "    @param mode: either 'training' or 'prediction'\n",
    "    \n",
    "    @return X_train: a list of dictionary, features data\n",
    "    @return Y_train: a list of labels\n",
    "    @return files_index: a list of MongoDB document id to identify the files  \n",
    "    \"\"\"\n",
    "    X_dat = []\n",
    "    Y_dat = []\n",
    "    files_index = []\n",
    "    if mode not in ['training', 'prediction']:\n",
    "        print('Invalid mode for this function')\n",
    "        return None\n",
    "    cnt = 0\n",
    "    for doc in target_docs:\n",
    "        # check whether is a valid label for training mode\n",
    "        if mode == 'training':\n",
    "            valid = False\n",
    "            for label in labels:\n",
    "                if doc['classifications'][class_n] == label:\n",
    "                    valid = True\n",
    "        else:\n",
    "            valid = True\n",
    "        # if it's valid\n",
    "        if valid:\n",
    "            features = {}\n",
    "            for feature in feature_list:\n",
    "                try:\n",
    "                    dict1 = doc[feature]\n",
    "                    features.update(dict1)\n",
    "                except KeyError:\n",
    "                    print(\"File: \", doc['filename'], \"can't find feature\", feature)\n",
    "            # if this data entries has no features\n",
    "            if features:\n",
    "                # add features\n",
    "                X_dat.append(features)\n",
    "                if mode == 'training':\n",
    "                    Y_dat.append(doc['classifications'][class_n])\n",
    "                files_index.append((doc['_id'], doc['filename'], doc['country']))\n",
    "    if mode == 'training':\n",
    "        return X_dat, Y_dat, files_index\n",
    "    if mode == 'prediction':\n",
    "        return X_dat, files_index\n",
    "        \n",
    "\n",
    "# X_dat, Y_dat, files_index = data_construct(docs, ['tc_features', 'topword_features'], \n",
    "#                                            mode = 'training', class_n='Commission', labels = ['yes', 'no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "def train_data_transform(X_train, Y_train, Y_map):\n",
    "    \"\"\"\n",
    "    a function to transform the data to fit into the classifier\n",
    "    @X_train: a list of dictionaries (features), note that there shouldn't be nan values in the data set \n",
    "    \"\"\"\n",
    "    # transform X\n",
    "    v= DictVectorizer(sparse=False)\n",
    "    X_train = v.fit_transform(X_train)\n",
    "    # transform Y\n",
    "    Y_train = [Y_map[label] for label in Y_train]\n",
    "    return X_train, Y_train, v.feature_names_, v.vocabulary_\n",
    "X_dat, Y_dat, feature_names, feature_index = train_data_transform(X_dat, Y_dat, Y_map={'yes':1, 'no':0})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num of data entries: \"+str(len(X_dat)))\n",
    "print(\"Num of features: \"+str(len(X_dat[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NB_feature_importances(clf_nb, feature_names):\n",
    "    fim_maps=[]\n",
    "    for j in range(len(clf_nb.feature_log_prob_)):\n",
    "        fim_map = {}\n",
    "        for i in range(len(feature_names)):\n",
    "            fim_map[feature_names[i]] = clf_nb.feature_log_prob_[j][i]\n",
    "        fim_map = sorted(fim_map.items(), key=lambda x: x[1], reverse=True)\n",
    "        fim_maps.append(fim_map)\n",
    "    return fim_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Benchmark model\n",
    "Before feature engineering, the following functions in PopulateCXfaresheet_new.py were run in sequence:\n",
    "- update_CXfaresheets_new\n",
    "- find_all_tourcodes\n",
    "- encode_tourcodes\n",
    "- Besides, the topwords features have already been created\n",
    "\n",
    "The benchmark model use tc_features and topword_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "def train_with_loo(X_dat, Y_dat, Clf, rs=None, balanced=False):\n",
    "    cnt = 0\n",
    "    loo = LeaveOneOut()\n",
    "    golds = [] \n",
    "    preds = []\n",
    "    for train_index, test_index in loo.split(X_dat):\n",
    "        cnt += 1\n",
    "        print(\"Training model: \", cnt)\n",
    "        # print(\"leave Out:\", test_index[0])\n",
    "        X_train, X_test = X_dat[train_index], X_dat[test_index]\n",
    "        y_train = [Y_dat[i] for i in train_index]\n",
    "        y_test = Y_dat[test_index[0]]\n",
    "        if rs:\n",
    "            if balanced:\n",
    "                clf = Clf(random_state=rs, class_weight=\"balanced\")\n",
    "            else:\n",
    "                clf = Clf(random_state=rs)         \n",
    "        else:\n",
    "            if balanced:\n",
    "                clf = Clf(class_weight=\"balanced\")\n",
    "            else:\n",
    "                clf = Clf()\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        preds.append(pred[0])\n",
    "        golds.append(y_test)\n",
    "    return golds, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "golds, preds = train_with_loo(X_dat, Y_dat, rs=25, Clf=DecisionTreeClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat, Y_dat, rs=25, Clf=RandomForestClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "golds, preds = train_with_loo(X_dat, Y_dat, BernoulliNB)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest performs the best out of the 3 models, since Random Forest is an ensemble version of Decision Tree, this shows that the model has potential to improve with more samples and proper feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Removing features with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# remove all features that are either one or zero (on or off) in more than 90% of the samples.\n",
    "sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "X_dat_new = sel.fit_transform(X_dat)\n",
    "mask = sel.get_support()\n",
    "feature_names_new = [feature_names[i] for i in range(len(feature_names)) if mask[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat_new, Y_dat, rs=25, Clf=RandomForestClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golds, preds = train_with_loo(X_dat_new, Y_dat, rs=25, Clf=DecisionTreeClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing features with low variance decrease the model performance, shouldn't use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Feature selection with feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importances from Decision Tree\n",
    "def get_feature_importances(clf1, feature_names):\n",
    "    fim_map = {}\n",
    "    for i in range(len(feature_names)):\n",
    "        fim_map[feature_names[i]] = clf1.feature_importances_[i]\n",
    "\n",
    "    fim_map = sorted(fim_map.items(), key=lambda x: x[1], reverse=True)\n",
    "    return fim_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier to get feature importances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=25)\n",
    "clf.fit(X_dat, Y_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fim_map = get_feature_importances(clf, feature_names_new)\n",
    "fim_map[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select with important features\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(clf, threshold=0.0001)\n",
    "model.fit(X_dat, Y_dat)\n",
    "X_dat_new = model.transform(X_dat)\n",
    "mask = model.get_support()\n",
    "feature_names_new = [feature_names[i] for i in range(len(feature_names)) if mask[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat_new, Y_dat, rs=25, Clf=RandomForestClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "golds, preds = train_with_loo(X_dat_new, Y_dat, rs=25, Clf=DecisionTreeClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with feature importance improves the performance of a single Decision Tree but not random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature creation with rules\n",
    "Rules for feature engineering:\n",
    "1. If BCODE in tourcodes then is highly possible is not a commission sheet\n",
    "2. If all the tourcode starts with number, then is highly possible is not a commission sheet\n",
    "3. Under Incentive agreement, the term 'travel' is in the coporate name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_tc_firstdigit_is_num(db, faresheet, search_dict={}):\n",
    "    \"\"\"\n",
    "    This function create feature tc_features.tc_firstdigit_isNum.\n",
    "    If all the tourcodes start with number, then tc_features.tc_firstdigit_isNum is updated as true\"\"\"\n",
    "    fs = db[faresheet]\n",
    "    docs = [doc for doc in fs.find(search_dict, {'tourcodes':1})]\n",
    "    cnt = 0\n",
    "    for doc in docs:\n",
    "        # check whether the first digit is numerical\n",
    "        tourcodes = doc['tourcodes']\n",
    "        tourcodes_fd = [t[0] for t in tourcodes]\n",
    "        tourcodes_fd_num = []\n",
    "        for t in tourcodes_fd:\n",
    "            try:\n",
    "                tourcodes_fd_num.append(int(t))\n",
    "            except ValueError:\n",
    "                pass\n",
    "        if len(tourcodes_fd_num) == len(tourcodes_fd):\n",
    "            fd_is_num = True\n",
    "        else:\n",
    "            fd_is_num = False\n",
    "        # record it to the collection\n",
    "        fs.update_one({'_id': doc['_id']},\n",
    "                      {'$set': {'tc_features.tc_firstdigit_isNum': fd_is_num}}) \n",
    "        cnt = cnt + 1\n",
    "        print(\"Updated: \", cnt)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_tc_firstdigit_is_num(db, faresheet, search_dict={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_tc_has_BCODE(db, faresheet, search_dict={}):\n",
    "    \"\"\"\n",
    "    This function create feature tc_features.tc_hasBCODE\n",
    "    If any of the tourcodes has BCODE, then tc_features.tc_hasBCODE is updated as true \n",
    "    \"\"\"\n",
    "    fs = db[faresheet]\n",
    "    docs = [doc for doc in fs.find(search_dict, {'tourcodes':1})]\n",
    "    cnt = 0\n",
    "    for doc in docs:\n",
    "        # check whether the first digit is numerical\n",
    "        tourcodes = doc['tourcodes']\n",
    "        tc_hasBCODE = [tc for tc in tourcodes if 'BCODE' in tc]\n",
    "        if len(tc_hasBCODE)>0:\n",
    "            hasBCODE=True\n",
    "        else:\n",
    "            hasBCODE=False            \n",
    "        # record it to the collection\n",
    "        fs.update_one({'_id': doc['_id']},\n",
    "                      {'$set': {'tc_features.tc_hasBCODE': hasBCODE}}) \n",
    "        cnt = cnt + 1\n",
    "        print(\"Updated: \", cnt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_tc_has_BCODE(db, faresheet, search_dict={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling with the new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc for doc in fs.find({'cases.commission_classification': \"training\"}, \n",
    "                               {'tc_features':1, 'topword_features':1, 'classifications':1, 'filename':1, 'country':1})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat, Y_dat, files_index = data_construct(docs, ['tc_features', 'topword_features'], \n",
    "                                           mode = 'training', class_n='Commission', labels = ['yes', 'no'])\n",
    "X_dat, Y_dat, feature_names, feature_index = train_data_transform(X_dat, Y_dat, Y_map={'yes':1, 'no':0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num of data entries: \"+str(len(X_dat)))\n",
    "print(\"Num of features: \"+str(len(X_dat[0])))\n",
    "len(X_dat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat, Y_dat, rs=25, Clf=RandomForestClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select with important features\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(clf, threshold=0.01)\n",
    "model.fit(X_dat, Y_dat)\n",
    "X_dat_new = model.transform(X_dat)\n",
    "mask = model.get_support()\n",
    "feature_names_new = [feature_names[i] for i in range(len(feature_names)) if mask[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat_new, Y_dat, rs=25, Clf=RandomForestClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "golds, preds = train_with_loo(X_dat_new, Y_dat, rs=25, Clf=DecisionTreeClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The new feature tc_firstdigit_isNum seems to be useful, it improves recall on commission predictions compared with previous validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Feature creation: corporate travel agreement\n",
    "corporate travel agreement has a high possibility of being a commission sheet except faresheets from countries LK, IT\n",
    "set keyword_features.cta as : \n",
    "\n",
    "\"appear\": the term appear but not country LK or IT, \n",
    "\n",
    "\"appear_LK_IT\": the term appear but is country LK or IT,, \n",
    "\n",
    "\"not appear\": the term does not appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cta_docs = [doc for doc in fs.find({ \"$text\": { \"$search\": \"\\\"CORPORATE TRAVEL AGREEMENT\\\"\"}, \n",
    "                                     },\n",
    "                                   {\"filename\":1, \"country\":1}\n",
    "                                    )] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update all as not appear first:\n",
    "db[faresheet].update_many(\n",
    "    {},\n",
    "    {\"$set\": {\"keyword_features.cta\":\"not appear\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the appear case\n",
    "for doc in cta_docs:\n",
    "    # appear case\n",
    "    if doc['country'] not in ['LK', 'IT']:\n",
    "        db[faresheet].update_one({\"_id\" : doc['_id']}, {\"$set\": {\"keyword_features.cta\":\"appear\"}}) \n",
    "    # appear_LK_IT case\n",
    "    if doc['country'] in ['LK', 'IT']:\n",
    "        db[faresheet].update_one({\"_id\" : doc['_id']}, {\"$set\": {\"keyword_features.cta\":\"appear_LK_IT\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_keyword_features_cta(db, faresheet, search_dict={}):\n",
    "    # get all CORPORATE TRAVEL AGREEMENT documents \n",
    "    cta_docs = [doc for doc in fs.find({ \"$text\": { \"$search\": \"\\\"CORPORATE TRAVEL AGREEMENT\\\"\"}, \n",
    "                                     },\n",
    "                                   {\"filename\":1, \"country\":1}\n",
    "                                    )]\n",
    "    # update all as not appear first:\n",
    "    db[faresheet].update_many(\n",
    "        {},\n",
    "        {\"$set\": {\"keyword_features.cta\":\"not appear\"}}\n",
    "    )\n",
    "    # update the appear case\n",
    "    for doc in cta_docs:\n",
    "        # appear case\n",
    "        if doc['country'] not in ['LK', 'IT']:\n",
    "            db[faresheet].update_one({\"_id\" : doc['_id']}, {\"$set\": {\"keyword_features.cta\":\"appear\"}}) \n",
    "        #appear_LK_IT case\n",
    "        if doc['country'] in ['LK', 'IT']:\n",
    "            db[faresheet].update_one({\"_id\" : doc['_id']}, {\"$set\": {\"keyword_features.cta\":\"appear_LK_IT\"}})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cta_LK_IT_docs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Feature creation: specifc form \n",
    "If it's ADHOC NOTIFICATION FORM or ONE-OFF ADHOC FIT/GROUP REQUEST, then it must be not commission and not filed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [doc for doc in fs.find({'teststring': {'$exists': True}}, \n",
    "                               {'teststring':1, 'filename':1})] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.DataFrame(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df['filename_lower'] = texts_df['filename'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [doc for doc in fs.find({'teststring': {'$exists': True}}, \n",
    "                               {'teststring':1, 'filename':1})] \n",
    "texts_df = pd.DataFrame(texts)\n",
    "texts_df['filename_lower'] = texts_df['filename'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update all as false by default\n",
    "# update all as not appear first:\n",
    "db[faresheet].update_many(\n",
    "        {},\n",
    "        {\"$set\": {\"keyword_features.one_off_adhoc_fg_request\":False}}\n",
    "    )\n",
    "# create keyword feature and update classification result for one-off adhoc fit/group request\n",
    "for index, row in texts_df.loc[texts_df['teststring'].str.contains('ONE-OFF ADHOC FIT/GROUP REQUEST')].iterrows():\n",
    "    db[faresheet].update_one({\"_id\" : row['_id']}, {\"$set\": {\"keyword_features.one_off_adhoc_fg_request\":True}})\n",
    "    db[faresheet].update_one({\"_id\" : row['_id']}, {\"$set\": {\"classifications.Commission\":\"no\"}})\n",
    "    db[faresheet].update_one({\"_id\" : row['_id']}, {\"$set\": {\"classifications.Filed\":\"no\"}})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update all as false by default\n",
    "db[faresheet].update_many(\n",
    "        {},\n",
    "        {\"$set\": {\"keyword_features.adhoc_noti_form\":False}}\n",
    "    )\n",
    "# create keyword feature and update classification result for ADHOC NOTIFICATION FORM\n",
    "for index, row in texts_df.loc[texts_df['teststring'].str.contains('ADHOC NOTIFICATION FORM')].iterrows():\n",
    "    db[faresheet].update_one({\"_id\" : row['_id']}, {\"$set\": {\"keyword_features.adhoc_noti_form\":True}})\n",
    "    db[faresheet].update_one({\"_id\" : row['_id']}, {\"$set\": {\"classifications.Commission\":\"no\"}})\n",
    "    db[faresheet].update_one({\"_id\" : row['_id']}, {\"$set\": {\"classifications.Filed\":\"no\"}}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc for doc in fs.find({'cases.commission_classification': \"training\"}, \n",
    "                               {'tc_features':1, 'topword_features':1, 'keyword_features':1, 'classifications':1, 'filename':1, 'country':1})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat, Y_dat, files_index = data_construct(docs, ['tc_features', 'keyword_features', 'topword_features'], \n",
    "                                           mode = 'training', class_n='Commission', labels = ['yes', 'no'])\n",
    "X_dat, Y_dat, feature_names, feature_index = train_data_transform(X_dat, Y_dat, Y_map={'yes':1, 'no':0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num of data entries: \"+str(len(X_dat)))\n",
    "print(\"Num of features: \"+str(len(X_dat[0])))\n",
    "len(X_dat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat, Y_dat, rs=25, Clf=RandomForestClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select with important features\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(clf, threshold=0.001)\n",
    "model.fit(X_dat, Y_dat)\n",
    "X_dat_new = model.transform(X_dat)\n",
    "mask = model.get_support()\n",
    "feature_names_new = [feature_names[i] for i in range(len(feature_names)) if mask[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat_new, Y_dat, rs=25, Clf=RandomForestClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try including some of the specific forms sheets in training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_form1 = [doc for doc in fs.find({'keyword_features.one_off_adhoc_fg_request': True}, \n",
    "                               {'tc_features':1, 'topword_features':1, 'keyword_features':1, 'classifications':1, 'filename':1, 'country':1})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_form2 = [doc for doc in fs.find({'keyword_features.adhoc_noti_form': True}, \n",
    "                               {'tc_features':1, 'topword_features':1, 'keyword_features':1, 'classifications':1, 'filename':1, 'country':1})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = doc_form1 + doc_form2 + docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat, Y_dat, files_index = data_construct(train_docs, ['tc_features', 'keyword_features', 'topword_features'], \n",
    "                                           mode = 'training', class_n='Commission', labels = ['yes', 'no'])\n",
    "X_dat, Y_dat, feature_names, feature_index = train_data_transform(X_dat, Y_dat, Y_map={'yes':1, 'no':0}) \n",
    "print(\"Num of data entries: \"+str(len(X_dat)))\n",
    "print(\"Num of features: \"+str(len(X_dat[0])))\n",
    "len(X_dat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without balancing the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat, Y_dat, rs=25, Clf=RandomForestClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wrongly classified files\n",
    "def get_wrong_files(golds, preds, files_index):\n",
    "    wrong_index = [(i, golds[i], preds[i]) for i in range(len(golds)) if golds[i]!=preds[i]]  \n",
    "    wrong_files = [files_index[wrong_index[i][0]] for i in range(len(wrong_index))]\n",
    "    print(\"Number of wrongly classified files:\", len(wrong_index))\n",
    "    for i in range(len(wrong_index)):\n",
    "        print(\"Wrongly classified file: \", wrong_files[i][1], wrong_files[i][2])\n",
    "        print(\"The true label is: \", wrong_index[i][1], \"Predicted as: \", wrong_index[i][2])\n",
    "    return wrong_index, wrong_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_index, wrong_files = get_wrong_files(golds, preds, files_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with balancing the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat, Y_dat, rs=25, Clf=RandomForestClassifier, balanced=True)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_index, wrong_files = get_wrong_files(golds, preds, files_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the weight of the class doesn't help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select with important features\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# train on all data to get feature importance\n",
    "clf = RandomForestClassifier(random_state=25)\n",
    "clf.fit(X_dat, Y_dat)\n",
    "model = SelectFromModel(clf, threshold=0.001)\n",
    "model.fit(X_dat, Y_dat)\n",
    "X_dat_new = model.transform(X_dat)\n",
    "mask = model.get_support()\n",
    "feature_names_new = [feature_names[i] for i in range(len(feature_names)) if mask[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat_new, Y_dat, rs=25, Clf=RandomForestClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))\n",
    "# print(\"number of wrongly classified files: \": file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_index, wrong_files = get_wrong_files(golds, preds, files_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selecting features with chi2/mutual information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "sel = SelectKBest(mutual_info_classif, k=100)\n",
    "X_dat_new = sel.fit_transform(X_dat, Y_dat)\n",
    "mask = sel.get_support()\n",
    "feature_names_new = [feature_names[i] for i in range(len(feature_names)) if mask[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat_new, Y_dat, rs=25, Clf=RandomForestClassifier)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))\n",
    "# print(\"number of wrongly classified files: \": file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_index, wrong_files = get_wrong_files(golds, preds, files_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using chi2/mutual information selection is not as effective as feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Feature creation: filename_features\n",
    "\n",
    "- create features to indicate whether these terms are in filename: BCODE, commission, agent, corporate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df['filename_lower'] = texts_df['filename'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df.loc[texts_df['filename_lower'].str.contains('b code')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df.loc[texts_df['filename_lower'].str.contains('bcode')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df.loc[texts_df['filename_lower'].str.contains('b_code')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df.loc[texts_df['teststring'].str.contains('commission')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df['filename_str'] = texts_df['filename'].apply(lambda x: x.replace('_', ' '))\n",
    "texts_df['filename_str'] = texts_df['filename_str'].apply(lambda x: x.replace('-', ' '))\n",
    "texts_df['filename_str'] = texts_df['filename_str'].apply(lambda x: x.replace(',', ' '))\n",
    "texts_df['filename_str'] = texts_df['filename_str'].apply(lambda x: x.replace(';', ' '))\n",
    "texts_df['filename_str'] = texts_df['filename_str'].apply(lambda x: x.replace('.', ' '))\n",
    "texts_df['filename_str'] = texts_df['filename_str'].apply(lambda x: x.replace('html', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df['filename_str'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = texts_df['teststring']+texts_df['filename_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Feature creation: tf-idf valus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=300, lowercase=False,\n",
    "                                   stop_words='english', analyzer='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidf_vectorizer.fit_transform(texts_df['teststring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feature_list = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feature_list[:158]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the number\n",
    "add_on_stopwords = tfidf_feature_list[:158]\n",
    "stopwords = list(tfidf_vectorizer.stop_words_) + add_on_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build with the number remove\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=300, lowercase=False,\n",
    "                                    analyzer='word', stop_words=stopwords)\n",
    "tfidf = tfidf_vectorizer.fit_transform(texts_df['teststring'])\n",
    "tfidf_feature_list = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feature_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidf_feature_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df['_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feature_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tfidf)):\n",
    "    row = tfidf[i]\n",
    "    print(texts_df['_id'][i])\n",
    "    # record tfidf \n",
    "    tfidf_features = {}\n",
    "    for j in range(len(row)):\n",
    "        tfidf_features[tfidf_feature_list[j]]: row[j]\n",
    "        print(tfidf_feature_list[j], row[j])\n",
    "        j+=1\n",
    "    i+=1\n",
    "    \n",
    "    if i>2:\n",
    "        break\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Produce Commission sheet prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs = [doc for doc in fs.find({'cases.commission_classification': \"training\"}, \n",
    "docs = [doc for doc in fs.find({'$or': [ { 'classifications.Commission': 'yes' }, { 'classifications.Commission': 'no' }]}, \n",
    "                               {'tc_features':1, 'topword_features':1, 'keyword_features':1, 'classifications':1, 'filename':1, 'country':1})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat, Y_dat, files_index = data_construct(docs, ['tc_features', 'topword_features', 'keyword_features'], \n",
    "                                           mode = 'training', class_n='Commission', labels = ['yes', 'no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat, Y_dat, feature_names, feature_index = train_data_transform(X_dat, Y_dat, Y_map={'yes':1, 'no':0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier to get feature importances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=25)\n",
    "clf.fit(X_dat, Y_dat)\n",
    "fim_map = get_feature_importances(clf, feature_names)\n",
    "fim_map[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat, Y_dat, rs=25, Clf=RandomForestClassifier, balanced=True)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))\n",
    "wrong_index, wrong_files = get_wrong_files(golds, preds, files_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose important features, threshold = 0\n",
    "important_features = [ f for f in fim_map if f[1]>0]\n",
    "# important_features\n",
    "# find important features indexes\n",
    "important_features_index = [feature_index[f[0]] for f in important_features]\n",
    "len(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_dat_if = [np.take(row, important_features_index) for row in X_dat] \n",
    "X_dat_if = np.array(X_dat_if)\n",
    "X_dat_if.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation training with importance features\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "golds, preds = train_with_loo(X_dat_if, Y_dat, rs=25, Clf=RandomForestClassifier, balanced=True)\n",
    "print(classification_report(golds, preds, target_names=['commission', 'not commission']))\n",
    "wrong_index, wrong_files = get_wrong_files(golds, preds, files_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier with all data\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_dat_if, Y_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find document to predict\n",
    "pred_docs = [doc for doc in fs.find({'lang': 'en'}, \n",
    "                               {'tc_features':1, 'topword_features':1, 'keyword_features':1, 'classifications':1, 'filename':1, 'country':1})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction the data\n",
    "pred_dat, pred_files_index = data_construct(pred_docs, ['tc_features', 'topword_features', 'keyword_features'], \n",
    "                                           mode = 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_list = [e[0] for e in important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data to fit in the classifier\n",
    "def predict_data_transform(pred_dat, feature_list):\n",
    "    v = DictVectorizer(sparse=False)\n",
    "    pred_train = v.fit_transform(pred_dat)\n",
    "    feature_index = [v.vocabulary_[f] for f in feature_list]\n",
    "    pred_train = [np.take(row, feature_index) for row in pred_train] \n",
    "    return pred_train\n",
    "X_pred = predict_data_transform(pred_dat, important_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(X_pred).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_map = {'1':'yes', '0':'no'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.update_many({}, {'$set': {'predictions.Commission': 'undefined'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_files_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fieid = 'predictions.Commission'\n",
    "preds = clf.predict(X_pred)\n",
    "preds = [predict_map[str(p)] for p in preds]\n",
    "cnt = 0\n",
    "for i in range(len(preds)):\n",
    "    cnt+=1\n",
    "    fs.update_one({'_id': pred_files_index[i][0]}, {'$set': {pred_fieid: preds[i]}})\n",
    "    print('Updating: ', cnt, pred_files_index[i], preds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rassure_nltk]",
   "language": "python",
   "name": "conda-env-rassure_nltk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
