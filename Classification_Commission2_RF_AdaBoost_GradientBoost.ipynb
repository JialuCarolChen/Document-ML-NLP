{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from raxutil.nlp.cat16utilities import *\n",
    "# from raxutil.nlp.chunker import *\n",
    "# from raxutil.nlp.faresheet import *\n",
    "# from raxutil.nlp.production import *\n",
    "# from raxutil.nlp.tagger import *\n",
    "# from raxutil.nlp.spellchecker import *\n",
    "\n",
    "from raxutil.ml.dataHandler import *\n",
    "from raxutil.ml.modelBuilder import *\n",
    "\n",
    "\n",
    "import cssutils\n",
    "from functools import reduce\n",
    "import os\n",
    "from os.path import basename\n",
    "import csv, ast\n",
    "from glob import glob\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.classify import MaxentClassifier \n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pymongo import TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlas_client=MongoClient('mongodb://gerald:heroku01@cluster0-shard-00-00-yvbwp.mongodb.net:27017,cluster0-shard-00-01-yvbwp.mongodb.net:27017,cluster0-shard-00-02-yvbwp.mongodb.net:27017/admin?replicaSet=Cluster0-shard-0&ssl=true')\n",
    "# client=MongoClient('mongodb://gerald:heroku01@127.0.0.1:27017')\n",
    "client = MongoClient(\"mongodb://raxPaper:vN9k32dXma@cluster0-shard-00-00-yvbwp.mongodb.net:27017,cluster0-shard-00-01-yvbwp.mongodb.net:27017,cluster0-shard-00-02-yvbwp.mongodb.net:27017/raxdb?replicaSet=Cluster0-shard-0&ssl=true&authSource=admin\")\n",
    "db=client.raxdb\n",
    "faresheet = 'CXfaresheets_new'\n",
    "fs = db['CXfaresheets_new']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Encode Cluster Features for US data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = DataCollector(db, faresheet)\n",
    "docs = collector.collect_for_train(country=['US', 'US_OFFLINES'], \n",
    "                                   fields=['filename', 'country', 'teststring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raxutil.ml.analysisTool import ClusterAnalyzer\n",
    "cluster_analyzer = ClusterAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing the best k\n",
    "choose_k(dat, k1=5, k2=15, v_min_df=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing the best k\n",
    "choose_k(dat, k1=2, k2=5, v_min_df=160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose k=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode cluster features \n",
    "dat = cluster_analyzer.find_clusters(dat, k=8, v_min_df=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the cluster feature to database\n",
    "print(\"Number of files to update: \", len(dat))\n",
    "cnt = 0\n",
    "for index, row in dat.iterrows():\n",
    "    print(\"Updating: \", cnt, row[\"filename\"], row[\"country\"])   \n",
    "    db[faresheet].update_one({\n",
    "        \"_id\": row[\"_id\"]\n",
    "    },\n",
    "    {\"$set\":{\"other_features.cluster\": \"US_\"+str(row[\"cluster\"])}}\n",
    "    )\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions stored in raxutil.ml.featureEngine\n",
    "def encode_cluster_feature(db, faresheet, analyzer, dat, k, v_min_df):\n",
    "    # encode cluster features \n",
    "    dat = analyzer.find_clusters(dat, k, v_min_df)\n",
    "    # update the cluster feature to database\n",
    "    print(\"Number of files to update: \", len(dat))\n",
    "    cnt = 0\n",
    "    for index, row in dat.iterrows():\n",
    "        print(\"Updating: \", cnt, row[\"filename\"], row[\"country\"])   \n",
    "        db[faresheet].update_one({\n",
    "            \"_id\": row[\"_id\"]\n",
    "        },\n",
    "        {\"$set\":{\"other_features.cluster\": \"US_\"+str(row[\"cluster\"])}}\n",
    "        )\n",
    "        cnt+=1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Encode one_off_adhoc_fg_request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc for doc in db[faresheet].find({}, {\"filename\":1, \"country\":1, \"teststring\":1})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = pd.DataFrame(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = docs_df['teststring'].str.contains(\"ONE-OFF ADHOC FIT/GROUP REQUEST\")\n",
    "mask2 = docs_df['country']=='US'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_df = docs_df.loc[mask1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create keyword feature and update classification result for one-off adhoc fit/group request\n",
    "for index, row in form_df.iterrows():\n",
    "    print(\"Updating: \", row[\"filename\"], row[\"country\"])\n",
    "    db[faresheet].update_one({\"_id\" : row['_id']}, {\"$set\": {\"keyword_features.one_off_adhoc_fg_request\":True}})\n",
    "    db[faresheet].update_one({\"_id\" : row['_id']}, {\"$set\": {\"classifications.Commission\":\"no\"}})\n",
    "    db[faresheet].update_one({\"_id\" : row['_id']}, {\"$set\": {\"classifications.Filed\":\"no\"}})   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Collect US data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = DataCollector(db, faresheet)\n",
    "docs = collector.collect_for_train(classification=\"Commission\", country=['US', 'US_OFFLINES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raxutil.ml.dataHandler import DataTransformer\n",
    "transformer = DataTransformer()\n",
    "X_dat, Y_dat, files_index = transformer.data_construct(target_docs=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat, Y_dat, feature_names, feature_index = transformer.train_data_transform(X_dat, Y_dat, Y_map={'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf1 = RandomForestClassifier(criterion=\"entropy\",random_state=1, class_weight=\"balanced\")\n",
    "clf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raxutil.ml.modelBuilder import train_with_loo, get_wrong_files\n",
    "golds, preds = train_with_loo(X_dat, Y_dat, clf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_index, wrong_files = get_wrong_files(golds, preds, files_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raxutil.ml.modelBuilder import get_feature_importances\n",
    "fim_map = get_feature_importances(clf1, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golds, preds = train_with_feature_importances(X_dat, Y_dat, clf, fim_map, feature_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_index, wrong_files = get_wrong_files(golds, preds, files_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "An AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost with Decission Tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf2 = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100)\n",
    "golds, preds = train_with_loo(X_dat, Y_dat, clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_index, wrong_files = get_wrong_files(golds, preds, files_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raxutil.ml.modelBuilder import get_feature_importances\n",
    "fim_map = get_feature_importances(clf2, feature_names)\n",
    "golds, preds = train_with_feature_importances(X_dat, Y_dat, clf2, fim_map, feature_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_index, wrong_files = get_wrong_files(golds, preds, files_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf3 = GradientBoostingClassifier(n_estimators = 100)\n",
    "golds, preds = train_with_loo(X_dat, Y_dat, clf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_index, wrong_files = get_wrong_files(golds, preds, files_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raxutil.ml.modelBuilder import get_feature_importances\n",
    "fim_map = get_feature_importances(clf3, feature_names)\n",
    "golds, preds = train_with_feature_importances(X_dat, Y_dat, clf3, fim_map, feature_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_index, wrong_files = get_wrong_files(golds, preds, files_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model: Ensemble of Random Forest, Gradient Boost, AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(criterion=\"entropy\",random_state=1, class_weight=\"balanced\")\n",
    "clf2 = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100)\n",
    "clf3 = GradientBoostingClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [clf1, clf2, clf3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raxutil.ml.dataHandler import DataTransformer\n",
    "\n",
    "def ensemble_models(clfs, X_dat, Y_dat, feature_index, X_pred, pred_feature_index=None, feature_select=True):\n",
    "    preds = {}\n",
    "    for i in range(len(clfs)):\n",
    "        clf = clfs[i]\n",
    "        print(clf)\n",
    "        if feature_select:\n",
    "            \n",
    "            clf.fit(X_dat, Y_dat)\n",
    "        \n",
    "            # get feature importances\n",
    "            fim_map = get_feature_importances(clf, feature_names)\n",
    "            # transform data set\n",
    "            important_features = [f for f in fim_map if f[1] > 0.0]\n",
    "            important_features_index = [feature_index[f[0]] for f in important_features]\n",
    "            X_dat_if = [np.take(row, important_features_index) for row in X_dat]\n",
    "            X_dat_if = np.array(X_dat_if)\n",
    "            print(\"model \", i, \" data shape: \", X_dat_if.shape)\n",
    "            # train with important features\n",
    "            clf.fit(X_dat_if, Y_dat)\n",
    "            \n",
    "            # transform prediction data and predict\n",
    "            preds[i] = predict_with_feature_importances(pred_X_dat, clf, fim_map, pred_feature_index, threshold=0.0)\n",
    "            \n",
    "        else:\n",
    "            clf.fit(X_dat, Y_dat)\n",
    "            preds[i] = clf.predict(X_pred)\n",
    "          \n",
    "    return preds        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = DataCollector(db, faresheet)\n",
    "pred_docs = collector.collect_for_train(country=['US', 'US_OFFLINES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raxutil.ml.dataHandler import DataTransformer\n",
    "transformer = DataTransformer()\n",
    "pred_X, pred_files_index = transformer.data_construct(target_docs=pred_docs, mode = 'predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X_dat, pred_feature_names, pred_feature_index = transformer.train_data_transform(pred_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_X_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1.fit(X_dat, Y_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ensemble_models(clfs, X_dat, Y_dat, feature_index, pred_X_dat, pred_feature_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = preds_df.mode(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.columns=[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"_id\"] = pred_files_index \n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(preds_df[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update predictions\n",
    "for index, row in preds_df.iterrows():\n",
    "    if row['pred']==1:\n",
    "        predict = 'yes'\n",
    "    if row['pred']==0:\n",
    "        predict = 'no'\n",
    "    db[faresheet].update_one({\"_id\": row[\"_id\"]}, \n",
    "                             {\"$set\": {\"predictions.Commission\":predict}})\n",
    "    print(row['_id'], predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check with cat35 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc for doc in db[faresheet].find({\"case\": \"commission_production\"}, {\"filename\":1, \"country\":1})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df_cat35 = pd.DataFrame(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df = pd.read_csv(\"/Users/chenjialu/Desktop/commission_US_list_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = comm_df.set_index([\"filename\", \"country\"]).join(comm_df_cat35.set_index([\"filename\", \"country\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = check_df[\"_id\"].isnull()\n",
    "mask2 = check_df[\"manual check\"]== \"yes\"\n",
    "check_df[mask1&mask2].to_csv(\"/Users/chenjialu/Desktop/commission_US_list_check.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rassure_nltk]",
   "language": "python",
   "name": "conda-env-rassure_nltk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
